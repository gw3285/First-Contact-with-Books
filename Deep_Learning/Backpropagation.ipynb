{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from math import exp\n",
    "\n",
    "# 목적: 인공신경망 가중치를 조정하는 방법 \n",
    "# backpropagation _ XOR\n",
    "# X: 학습 데이터 변수\n",
    "# D: 합습 데이터의 정답 변수\n",
    "\n",
    "# W1: 입력층 - 은닉층 가중치 행렬 변수\n",
    "# W2: 은닉층 - 출력층 가중치 행렬 변수\n",
    "\n",
    "# 입력층 2개 노드\n",
    "# 은닉층 2개 노드\n",
    "# 출려층 1개 노드\n",
    "# 활성함수 시그모이드\n",
    "# Backpropagation algorithm: SGD\n",
    "il_num = 2\n",
    "hl_num = 2\n",
    "ol_num = 1\n",
    "lr = 0.9\n",
    "N = 4\n",
    "    \n",
    "def sigmoid(x):\n",
    "    y = 1/(1+exp(x))\n",
    "    return y\n",
    "\n",
    "# 가중치와 학습 데이터를 넘겨받아 새로 갱신된 가중치를 반환합니다.\n",
    "# W1: 입력층-은닉층 가중치 행렬을 보관하는 변수\n",
    "# W2: 은닉층-출력층 가중치 행렬을 보관하는 변수\n",
    "# X: 학습 데이터의 입력 데이터\n",
    "# D: 학습 데이터의 정답 데이터\n",
    "def backkpropagationXOR(W1, W2, X, D):        \n",
    "    for k in range(N):\n",
    "        x = X[k]\n",
    "        d = D[k]\n",
    "        hl_v = np.array([0.0, 0.0])\n",
    "        hl_o = np.array([0.0, 0.0])\n",
    "        ol_v = 0.0\n",
    "        y = 0.0\n",
    "        d_h = np.array([0.0, 0.0])\n",
    "        \n",
    "        # 학습\n",
    "        # 입력층 - 은닉층\n",
    "        for i in range(len(W1)):\n",
    "            for j in range(len(x)):\n",
    "                hl_v[i] = hl_v[i] + W1[i][j]*x[j]\n",
    "            hl_o[i] = sigmoid(hl_v[i])\n",
    "        \n",
    "        # 은닉층 - 출력층\n",
    "        for i in range(len(W2)):\n",
    "            for j in range(len(hl_o)):\n",
    "                ol_v = ol_v + W2[i][j]*hl_o[j]\n",
    "        y = sigmoid(ol_v)\n",
    "        \n",
    "        # 오차\n",
    "        # 출력층\n",
    "        e_o = d - y\n",
    "        d_o = y*(1-y)*e_o\n",
    "        \n",
    "        #print(str(d)+\"-\"+str(y)+\"=\"+str(e_o))\n",
    "        \n",
    "        # 은닉층\n",
    "        e_h = np.transpose(W2)*d_o\n",
    "        print(e_h[0][0])\n",
    "        \n",
    "        ### 여기 부분... \n",
    "        for i in range(len(W1)):\n",
    "            \n",
    "            for j in range():\n",
    "            d_h[i] = hl_o[i]*(1-hl_o[i])*e_h[i]\n",
    "            d_w_h = lr * d_h[i] * np.transpose(x)[i]\n",
    "            W1[i] = W1[i] + d_w_h\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(len(W2)):\n",
    "            d_w_o = lr * d_o * np.transpose(hl_o)\n",
    "            W2[i] = W2[i] + d_w_o\n",
    "        \n",
    "    return [W1, W2]\n",
    "\n",
    "# 학습 데이터를 하나 꺼내 델타 규칙에 따라 가중치 갱신값(dw)을 계산하고, 이 값으로 신경망의 가중치를\n",
    "# 새로 갱신하는 과정은 \n",
    "# 은닉층이 있어 신경망의 출력값을 계산할 때 두 번에 걸쳐 sigmoid 함수를 호출하는 점과 다음과 같이 출력 노드의\n",
    "# 델타를 역전파시켜 은닉 노드들의 델타(delta)를 계산하는 과정이 추가되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.03702960430657341\n",
      "0.05012142347487718\n",
      "0.05823155241089\n",
      "-0.04877817725662475\n",
      "\n",
      "-0.038756219595964536\n",
      "0.05458771401988242\n",
      "0.06280690122903214\n",
      "-0.051515577257142044\n",
      "\n",
      "-0.04044853259329007\n",
      "0.05934885174924391\n",
      "0.06766796600472585\n",
      "-0.054352722516167594\n",
      "\n",
      "-0.042087330850171245\n",
      "0.06441242681035023\n",
      "0.072818963194902\n",
      "-0.05728649396112405\n",
      "\n",
      "-0.043651875959420376\n",
      "0.06978345596088423\n",
      "0.07826112503112446\n",
      "-0.06031334158308891\n",
      "\n",
      "-0.04512028218634783\n",
      "0.07546386756046669\n",
      "0.0839922337856528\n",
      "-0.0634294743125302\n",
      "\n",
      "-0.046470025535331055\n",
      "0.0814520178811406\n",
      "0.09000622066803952\n",
      "-0.06663109904324381\n",
      "\n",
      "-0.047678579638622154\n",
      "0.08774227788859067\n",
      "0.09629287123375596\n",
      "-0.06991470125055393\n",
      "\n",
      "-0.048724162119192393\n",
      "0.09432473384125711\n",
      "0.10283768028665198\n",
      "-0.07327735376029242\n",
      "\n",
      "-0.04958656059607736\n",
      "0.10118504519357983\n",
      "0.10962189534855643\n",
      "-0.07671703448586426\n",
      "\n",
      "-0.05024799297958426\n",
      "0.10830449803458103\n",
      "0.1166227779181517\n",
      "-0.08023292929521278\n",
      "\n",
      "-0.05069394443829257\n",
      "0.11566028091196602\n",
      "0.12381409588618464\n",
      "-0.0838256935814793\n",
      "\n",
      "-0.0509139159478775\n",
      "0.12322599265117525\n",
      "0.13116683973608118\n",
      "-0.08749764640963505\n",
      "\n",
      "-0.05090201890623236\n",
      "0.13097237019019445\n",
      "0.1386501319166087\n",
      "-0.09125287471999617\n",
      "\n",
      "-0.05065735827360201\n",
      "0.1388682012373552\n",
      "0.14623227639736286\n",
      "-0.09509723184102986\n",
      "\n",
      "-0.05018416300229187\n",
      "0.14688136526201043\n",
      "0.15388187765676148\n",
      "-0.09903822372887756\n",
      "\n",
      "-0.04949164543389604\n",
      "0.15497993059440957\n",
      "0.1615689484890599\n",
      "-0.10308478662969624\n",
      "\n",
      "-0.048593597672227165\n",
      "0.16313322813676578\n",
      "0.16926592603788296\n",
      "-0.10724696972185875\n",
      "\n",
      "-0.04750775864640677\n",
      "0.17131282477086945\n",
      "0.17694852550940912\n",
      "-0.11153554429177136\n",
      "\n",
      "-0.046255006660475786\n",
      "0.17949333151074545\n",
      "0.18459637931477238\n",
      "-0.11596156608098962\n",
      "\n",
      "-0.04485844562412367\n",
      "0.18765300055935002\n",
      "0.1921934326946309\n",
      "-0.12053591915989026\n",
      "\n",
      "-0.04334245739169995\n",
      "0.19577408828159937\n",
      "0.1997280912840397\n",
      "-0.12526886820843083\n",
      "\n",
      "-0.0417317879931887\n",
      "0.2038429839675127\n",
      "0.20719313792241822\n",
      "-0.13016964209725831\n",
      "\n",
      "-0.04005072381820753\n",
      "0.21185012389403038\n",
      "0.21458545261631418\n",
      "-0.1352460661292874\n",
      "\n",
      "-0.038322397727479765\n",
      "0.2197897244501416\n",
      "0.2219055795890217\n",
      "-0.1405042542370982\n",
      "\n",
      "-0.03656824754999001\n",
      "0.22765937611912115\n",
      "0.22915718881048816\n",
      "-0.1459483667023684\n",
      "\n",
      "-0.034807633028840726\n",
      "0.23545954224692803\n",
      "0.2363464773381427\n",
      "-0.15158043417596415\n",
      "\n",
      "-0.03305760379486474\n",
      "0.24319300393128865\n",
      "0.24348154984372042\n",
      "-0.1574002452448907\n",
      "\n",
      "-0.031332801285365\n",
      "0.25086428660776966\n",
      "0.25057180962223347\n",
      "-0.16340529256913885\n",
      "\n",
      "-0.02964547180993883\n",
      "0.2584790965718106\n",
      "0.25762738274868974\n",
      "-0.16959077155989924\n",
      "\n",
      "-0.028005565748714434\n",
      "0.2660437880958577\n",
      "0.2646585900483069\n",
      "-0.17594962543787385\n",
      "\n",
      "-0.026420898382447\n",
      "0.2735648749344975\n",
      "0.27167547491282934\n",
      "-0.18247263099637337\n",
      "\n",
      "-0.024897350231752043\n",
      "0.2810485944129005\n",
      "0.2786873900578068\n",
      "-0.18914852020206066\n",
      "\n",
      "-0.023439088217241742\n",
      "0.2885005281717319\n",
      "0.28570264308469034\n",
      "-0.19596413363689685\n",
      "\n",
      "-0.022048792786555756\n",
      "0.2959252809407421\n",
      "0.2927281989850963\n",
      "-0.2029046025139011\n",
      "\n",
      "-0.020727879913650885\n",
      "0.30332621721052494\n",
      "0.2997694371804029\n",
      "-0.209953556446514\n",
      "\n",
      "-0.019476710260212762\n",
      "0.310705255056169\n",
      "0.30682996095871395\n",
      "-0.2170933542422717\n",
      "\n",
      "-0.018294780643464723\n",
      "0.3180627163000696\n",
      "0.31391145788734304\n",
      "-0.2243053347151645\n",
      "\n",
      "-0.017180895230928465\n",
      "0.3253972323637691\n",
      "0.3210136106123294\n",
      "-0.2315700839140488\n",
      "\n",
      "-0.016133315603655014\n",
      "0.33270570527661286\n",
      "0.3281340581324095\n",
      "-0.23886771434166787\n",
      "\n",
      "-0.015149890058560772\n",
      "0.3399833231738935\n",
      "0.3352684079461118\n",
      "-0.2461781508203893\n",
      "\n",
      "-0.014228163339435393\n",
      "0.3472236290973618\n",
      "0.3424102992850325\n",
      "-0.25348141679569175\n",
      "\n",
      "-0.013365468479665988\n",
      "0.3544186409572478\n",
      "0.3495515169113405\n",
      "-0.2607579142055083\n",
      "\n",
      "-0.012559002686512903\n",
      "0.36155901915982563\n",
      "0.3566821537008427\n",
      "-0.2679886897115546\n",
      "\n",
      "-0.011805889265108765\n",
      "0.36863427675531074\n",
      "0.3637908185577146\n",
      "-0.27515568017884123\n",
      "\n",
      "-0.011103227526386098\n",
      "0.3756330251842542\n",
      "0.3708648842802345\n",
      "-0.2822419308420694\n",
      "\n",
      "-0.010448132491214556\n",
      "0.38254324700063996\n",
      "0.3778907680298534\n",
      "-0.2892317805964162\n",
      "\n",
      "-0.009837766026910284\n",
      "0.3893525855396343\n",
      "0.3848542352782534\n",
      "-0.2961110102251726\n",
      "\n",
      "-0.009269360856760953\n",
      "0.3960486405691332\n",
      "0.3917407167366332\n",
      "-0.3028669510140668\n",
      "\n",
      "-0.008740238685752593\n",
      "0.4026192586591656\n",
      "0.39853562698511646\n",
      "-0.3094885529612231\n",
      "\n",
      "-0.00824782349793267\n",
      "0.4090528073935172\n",
      "0.4052246734293594\n",
      "-0.3159664135245381\n",
      "\n",
      "-0.007789650909916626\n",
      "0.4153384236243516\n",
      "0.4117941448475347\n",
      "-0.32229276941865487\n",
      "\n",
      "-0.007363374314632647\n",
      "0.42146622764515834\n",
      "0.41823117010259125\n",
      "-0.32846145527309817\n",
      "\n",
      "-0.0069667684206664296\n",
      "0.4274274972775172\n",
      "0.42452393945786737\n",
      "-0.33446783392035623\n",
      "\n",
      "-0.0065977306848981525\n",
      "0.4332147982390742\n",
      "0.4306618831715209\n",
      "-0.3403087036675656\n",
      "\n",
      "-0.006254281047740088\n",
      "0.4388220695761\n",
      "0.4366358044527824\n",
      "-0.3459821881260083\n",
      "\n",
      "-0.005934560308740315\n",
      "0.4442446652095715\n",
      "0.442437966237161\n",
      "-0.35148761406799145\n",
      "\n",
      "-0.0056368274229007505\n",
      "0.4494793545995404\n",
      "0.4480621333995113\n",
      "-0.35682538241122697\n",
      "\n",
      "-0.005359455952072434\n",
      "0.45452428706862524\n",
      "0.4535035738366025\n",
      "-0.361996836867769\n",
      "\n",
      "-0.00510092986876893\n",
      "0.45937892538629077\n",
      "0.45875902322902756\n",
      "-0.3670041341105443\n",
      "\n",
      "-0.004859838879559104\n",
      "0.46404395479742494\n",
      "0.4638266192027398\n",
      "-0.371850118572201\n",
      "\n",
      "-0.004634873410139262\n",
      "0.46852117382059144\n",
      "0.46870581106627807\n",
      "-0.37653820425431095\n",
      "\n",
      "-0.004424819372917384\n",
      "0.4728133729125597\n",
      "0.4733972513498964\n",
      "-0.38107226523256776\n",
      "\n",
      "-0.0042285528195053065\n",
      "0.4769242065825287\n",
      "0.4779026750899346\n",
      "-0.3854565359246728\n",
      "\n",
      "-0.004045034564245985\n",
      "0.4808580638327725\n",
      "0.4822247722697636\n",
      "-0.3896955216588115\n",
      "\n",
      "-0.0038733048503762457\n",
      "0.4846199409880536\n",
      "0.4863670581322139\n",
      "-0.3937939196483566\n",
      "\n",
      "-0.0037124781173836253\n",
      "0.4882153201280801\n",
      "0.4903337452951097\n",
      "-0.39775655014108924\n",
      "\n",
      "-0.003561737916413917\n",
      "0.4916500555141352\n",
      "0.4941296207967943\n",
      "-0.4015882972617002\n",
      "\n",
      "-0.0034203320101446645\n",
      "0.49493026964495107\n",
      "0.4977599304231924\n",
      "-0.40529405889412573\n",
      "\n",
      "-0.0032875676843102187\n",
      "0.49806225991461905\n",
      "0.5012302719579209\n",
      "-0.4088787048433135\n",
      "\n",
      "-0.003162807290006389\n",
      "0.5010524162901294\n",
      "0.5045464983746215\n",
      "-0.41234704246193293\n",
      "\n",
      "-0.0030454640289705815\n",
      "0.5039071499807889\n",
      "0.5077146314667785\n",
      "-0.41570378891464416\n",
      "\n",
      "-0.002934997988169007\n",
      "0.5066328327312873\n",
      "0.5107407859866201\n",
      "-0.4189535492702893\n",
      "\n",
      "-0.0028309124251543346\n",
      "0.5092357461245738\n",
      "0.5136311040365369\n",
      "-0.42210079965177816\n",
      "\n",
      "-0.0027327503017019034\n",
      "0.5117220401171028\n",
      "0.5163916992148033\n",
      "-0.42514987472704285\n",
      "\n",
      "-0.0026400910600988966\n",
      "0.5140976999335335\n",
      "0.5190286098509246\n",
      "-0.42810495888629396\n",
      "\n",
      "-0.0025525476340533307\n",
      "0.5163685204068744\n",
      "0.52154776056241\n",
      "-0.4309700805163811\n",
      "\n",
      "-0.00246976368441188\n",
      "0.5185400868506777\n",
      "0.523954931312119\n",
      "-0.4337491088489352\n",
      "\n",
      "-0.0023914110486350634\n",
      "0.5206177615810288\n",
      "0.5262557331323036\n",
      "-0.4364457529227717\n",
      "\n",
      "-0.002317187392187339\n",
      "0.5226066752582585\n",
      "0.5284555896981311\n",
      "-0.4390635622611656\n",
      "\n",
      "-0.0022468140495777115\n",
      "0.5245117222838038\n",
      "0.5305597239712906\n",
      "-0.4416059289200917\n",
      "\n",
      "-0.002180034042662323\n",
      "0.5263375595603695\n",
      "0.5325731491862229\n",
      "-0.44407609061385395\n",
      "\n",
      "-0.0021166102639300116\n",
      "0.5280886079988284\n",
      "0.5345006635119387\n",
      "-0.44647713466955813\n",
      "\n",
      "-0.0020563238127811723\n",
      "0.5297690562297583\n",
      "0.5363468477869096\n",
      "-0.44881200260168624\n",
      "\n",
      "-0.001998972473232844\n",
      "0.5313828660487798\n",
      "0.5381160657898418\n",
      "-0.4510834951328633\n",
      "\n",
      "-0.001944369322000124\n",
      "0.5329337791913623\n",
      "0.5398124665729083\n",
      "-0.4532942775171276\n",
      "\n",
      "-0.00189234145648429\n",
      "0.534425325093636\n",
      "0.5414399884445684\n",
      "-0.45544688504800845\n",
      "\n",
      "-0.001842728832815869\n",
      "0.53586082935053\n",
      "0.5430023642454318\n",
      "-0.4575437286559249\n",
      "\n",
      "-0.0017953832047357958\n",
      "0.5372434226311943\n",
      "0.5445031276121015\n",
      "-0.459587100518268\n",
      "\n",
      "-0.0017501671547343965\n",
      "0.5385760498543418\n",
      "0.5459456199703502\n",
      "-0.4615791796214164\n",
      "\n",
      "-0.0017069532094939985\n",
      "0.5398614794631779\n",
      "0.5473329980403149\n",
      "-0.46352203722725493\n",
      "\n",
      "-0.0016656230322879197\n",
      "0.5411023126714255\n",
      "0.5486682416728298\n",
      "-0.46541764220785786\n",
      "\n",
      "-0.0016260666855698578\n",
      "0.5423009925790881\n",
      "0.5499541618678225\n",
      "-0.4672678662211826\n",
      "\n",
      "-0.0015881819575396384\n",
      "0.5434598130794952\n",
      "0.5511934088532544\n",
      "-0.4690744887081761\n",
      "\n",
      "-0.0015518737469906569\n",
      "0.5445809274983898\n",
      "0.552388480126737\n",
      "-0.4708392016978667\n",
      "\n",
      "-0.0015170535012305397\n",
      "0.5456663569217555\n",
      "0.5535417283821631\n",
      "-0.472563614412024\n",
      "\n",
      "-0.0014836387023187598\n",
      "0.5467179981822299\n",
      "0.5546553692607641\n",
      "-0.4742492576649913\n",
      "\n",
      "-0.0014515523972838463\n",
      "0.5477376314846784\n",
      "0.5557314888803936\n",
      "-0.47589758805750654\n",
      "\n",
      "-0.00142072276836936\n",
      "0.5487269276601695\n",
      "0.5567720511088485\n",
      "-0.4775099919658453\n",
      "\n",
      "-0.0013910827397132298\n",
      "0.5496874550445332\n",
      "0.5577789045569731\n",
      "-0.4790877893295883\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-8431c7e1f9f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# 은닉층 - 출력층\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhl_o\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mol_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mol_v\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mhl_o\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mol_v\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "W1 = np.array([[0.6, 0.4], [0.3, 0.8]])\n",
    "W2 = np.array([[0.4, 0.5]])\n",
    "X = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
    "D = np.array([0.0, 1.0, 1.0, 0.0])\n",
    "\n",
    "for i in range(100):\n",
    "    W = backkpropagationXOR(W1, W2, X, D)\n",
    "    W1 = W[0]\n",
    "    W2 = W[1]\n",
    "    print(\"\")\n",
    "\n",
    "    \n",
    "for k in range(N):\n",
    "    x = X[k]\n",
    "    hl_v = np.array([0.0, 0.0])\n",
    "    hl_o = np.array([0.0, 0.0])\n",
    "    ol_v = 0.0\n",
    "    y = 0.0\n",
    "    \n",
    "    # 입력층 - 은닉층\n",
    "    for i in range(len(W1)):\n",
    "        for j in range(len(x)):\n",
    "            hl_v[i] = hl_v[i] + W1[i][j]*x[j]\n",
    "        hl_o[i] = sigmoid(hl_v[i])\n",
    "\n",
    "    # 은닉층 - 출력층\n",
    "    for i in range(len(hl_o)):\n",
    "        ol_v = ol_v + W2[i]*hl_o[i]\n",
    "    y = sigmoid(ol_v)\n",
    "\n",
    "    #print(y)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict= [array([[0.16879787],\n",
      "       [0.82265145],\n",
      "       [0.82073253],\n",
      "       [0.2327794 ]], dtype=float32)]\n",
      "result= [[[0]\n",
      "  [1]\n",
      "  [1]\n",
      "  [0]]]\n"
     ]
    }
   ],
   "source": [
    "# tensorflow로 구현한 XOR 해결법\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# trainint set\n",
    "X_train = np.array( [[0,0], [0,1], [1,0], [1,1]])\n",
    "D_train = np.array( [[0], [1], [1], [0]] )\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "D = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "# variable\n",
    "W1 = tf.Variable(tf.truncated_normal([2,2]))\n",
    "b1 = tf.Variable(tf.zeros([2]))\n",
    "W2 = tf.Variable(tf.truncated_normal([2,1]))\n",
    "b2 = tf.Variable(tf.zeros([1]), dtype=tf.float32)\n",
    "\n",
    "# model\n",
    "H_V = tf.matmul(X, W1)+b1\n",
    "H_O = tf.sigmoid(H_V)\n",
    "O_V = tf.matmul(H_O, W2)+b2\n",
    "Y = tf.sigmoid(O_V)\n",
    "\n",
    "learn_rate = 0.1\n",
    "Cost = tf.reduce_mean(tf.reduce_sum(tf.square(Y-D), 1))\n",
    "train = tf.train.GradientDescentOptimizer(learn_rate).minimize(Cost)\n",
    "\n",
    "predict = Y\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(10000):\n",
    "    _train, _Cost = sess.run([train, Cost], feed_dict={X:X_train, D:D_train})\n",
    "    #print( \"cost=\", _Cost)    \n",
    "\n",
    "_predict = sess.run([predict], feed_dict={X:X_train})\n",
    "print(\"predict=\", _predict)\n",
    "print(\"result=\", np.array(np.array(_predict)>=0.5, np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6 0.4]\n",
      " [0.3 0.8]]\n",
      "[[0.4 0.5]]\n",
      "[[0.6 0.3]\n",
      " [0.4 0.8]]\n",
      "[[0.4]\n",
      " [0.5]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import exp\n",
    "\n",
    "#print(np.array( [ [1, 2, 3], [4, 5, 6] ]))\n",
    "\n",
    "#x  = np.array([1.0, 1.1, 1.2]).reshape((1,3))\n",
    "#x = np.arange(3).reshape((1,3))\n",
    "#print(x)\n",
    "#x_t = np.transpose(x)\n",
    "#print(x_t)\n",
    "\n",
    "#print(exp(0))\n",
    "#y = 1/(1+exp(0.0))\n",
    "\n",
    "\n",
    "W1 = np.array([[0.6, 0.4], [0.3, 0.8]])\n",
    "W2 = np.array([[0.4, 0.5]])\n",
    "X = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
    "D = np.array([0.0, 1.0, 1.0, 0.0])\n",
    "\n",
    "print(W1)\n",
    "print(W2)\n",
    "print(np.transpose(W1))\n",
    "print(np.transpose(W2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
