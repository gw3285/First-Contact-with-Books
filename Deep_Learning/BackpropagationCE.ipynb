{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 목적: 인공신경망 가중치를 조정하는 방법 \n",
    "# backpropagation _ XOR\n",
    "# X: 학습 데이터 변수\n",
    "# D: 합습 데이터의 정답 변수\n",
    "\n",
    "# W1: 입력층 - 은닉층 가중치 행렬 변수\n",
    "# W2: 은닉층 - 출력층 가중치 행렬 변수\n",
    "\n",
    "# 입력층 2개 노드\n",
    "# 은닉층 2개 노드\n",
    "# 출려층 1개 노드\n",
    "# 활성함수 시그모이드\n",
    "# Backpropagation algorithm: SGD\n",
    "# learning rate가 0.9일때 4번째 데이터가 학습이 잘 안되었습니다.\n",
    "# 비용함수에서 왔다갔다가 많이 이루어진거 같네요\n",
    "# 앞으로 learning rate는 작게하는게 좋을거 같습니다.\n",
    "\n",
    "N = 4\n",
    "\n",
    "def sigmoid(x):\n",
    "    y = 1/(1+np.exp(-x))\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치와 학습 데이터를 넘겨받아 새로 갱신된 가중치를 반환합니다.\n",
    "# W1: 입력층-은닉층 가중치 행렬을 보관하는 변수\n",
    "# W2: 은닉층-출력층 가중치 행렬을 보관하는 변수\n",
    "# X: 학습 데이터의 입력 데이터\n",
    "# D: 학습 데이터의 정답 데이터\n",
    "\n",
    "lr = 0.2\n",
    "N = 4\n",
    "\n",
    "def backkpropagationCE(W1, W2, X, D):        \n",
    "    for k in range(N):\n",
    "        x = X[k]\n",
    "        d = D[k]\n",
    "        hidden_v = np.matrix([[0.0], [0.0]])\n",
    "        hidden_y = np.matrix([[0.0], [0.0]])\n",
    "        hidden_delta = np.matrix([[0.0], [0.0]])\n",
    "        output_v = np.matrix([[0.0]])\n",
    "        output_y = np.matrix([[0.0]])\n",
    "        output_delta = np.matrix([[0.0]])\n",
    "        \n",
    "        # 학습\n",
    "        # 입력층 - 은닉층\n",
    "        hidden_v = np.matmul(W1, np.transpose(x))\n",
    "        hidden_y = sigmoid(hidden_v)\n",
    "            \n",
    "        # 은닉층 - 출력층\n",
    "        output_v = np.matmul(W2, hidden_y)\n",
    "        output_y = sigmoid(output_v)\n",
    "        \n",
    "        # 오차\n",
    "        # 출력층\n",
    "        output_err = d - output_y\n",
    "        output_delta = output_err\n",
    "        \n",
    "        # 은닉층 오차\n",
    "        hidden_err = np.matmul(np.transpose(W2), output_delta)\n",
    "        \n",
    "        # 은닉층 델타\n",
    "        for i in range(len(hidden_err)): \n",
    "            hidden_delta[i] = hidden_y[i]*(1-hidden_y[i])*hidden_err[i]\n",
    "        \n",
    "        # 가중치 조정\n",
    "        # 입력층 - 가중치\n",
    "        #print(hidden_delta)\n",
    "        #print(x)\n",
    "        #print(W1)\n",
    "        #print()\n",
    "        for i in range(len(W1)):\n",
    "            delta_weight1 = lr*np.matmul(hidden_delta[i], x)\n",
    "            W1[i] = W1[i] + delta_weight1\n",
    "            \n",
    "        # 은닉층 - 출력층\n",
    "        delta_weight2 = lr*np.matmul(output_delta, np.transpose(hidden_y))\n",
    "        W2 = W2 + delta_weight2\n",
    "        \n",
    "    return [W1, W2]\n",
    "\n",
    "# 학습 데이터를 하나 꺼내 델타 규칙에 따라 가중치 갱신값(dw)을 계산하고, 이 값으로 신경망의 가중치를\n",
    "# 새로 갱신하는 과정은 \n",
    "# 은닉층이 있어 신경망의 출력값을 계산할 때 두 번에 걸쳐 sigmoid 함수를 호출하는 점과 다음과 같이 출력 노드의\n",
    "# 델타를 역전파시켜 은닉 노드들의 델타(delta)를 계산하는 과정이 추가되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01922588]]\n",
      "[[0.98696576]]\n",
      "[[0.98710146]]\n",
      "[[0.01922588]]\n"
     ]
    }
   ],
   "source": [
    "ran_w1 = np.random.rand(4)\n",
    "arr_w1 = ran_w1.reshape(2,2)\n",
    "W1 = np.asmatrix(arr_w1, dtype=float)\n",
    "\n",
    "ran_w2 = np.random.rand(2)\n",
    "arr_w2 = ran_w2.reshape(1,2)\n",
    "W2 = np.asmatrix(arr_w2, dtype=float)\n",
    "\n",
    "X = np.matrix([[0.0,0.0], [1.0,0.0], [0.0,1.0], [0.0,0.0]], dtype=float)\n",
    "D = np.matrix([[0.0], [1.0], [1.0], [0.0]], dtype=float)\n",
    "\n",
    "#input 행렬에 정렬 방법에 따라 훈련 방법이 달라집니다.\n",
    "\n",
    "for i in range(1000):\n",
    "    W = backkpropagationCE(W1, W2, X, D)\n",
    "    W1 = W[0]\n",
    "    W2 = W[1]\n",
    "    \n",
    "for k in range(N):\n",
    "    x = X[k]\n",
    "    hidden_v = np.matrix([[0.0], [0.0]])\n",
    "    hidden_y = np.matrix([[0.0], [0.0]])\n",
    "    output_v = np.matrix([[0.0]])\n",
    "    output_y = np.matrix([[0.0]])\n",
    "        \n",
    "    # 입력층 - 은닉층\n",
    "    hidden_v = np.matmul(W1, np.transpose(x))\n",
    "    hidden_y = sigmoid(hidden_v)\n",
    "\n",
    "    # 은닉층 - 출력층\n",
    "    output_v = np.matmul(W2, hidden_y)\n",
    "    output_y = sigmoid(output_v)\n",
    "    \n",
    "    print(output_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict= [array([[0.00125576],\n",
      "       [0.99826944],\n",
      "       [0.998831  ],\n",
      "       [0.00109024]], dtype=float32)]\n",
      "result= [[[0]\n",
      "  [1]\n",
      "  [1]\n",
      "  [0]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# trainint set\n",
    "X_train = np.array( [[0,0], [0,1], [1,0], [1,1]])\n",
    "D_train = np.array( [[0], [1], [1], [0]] )\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "D = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "# variable\n",
    "W1 = tf.Variable(tf.truncated_normal([2,2]), dtype=tf.float32)\n",
    "b1 = tf.Variable(tf.zeros([2]), dtype=tf.float32)\n",
    "W2 = tf.Variable(tf.truncated_normal([2,1]), dtype=tf.float32)\n",
    "b2 = tf.Variable(tf.zeros([1]), dtype=tf.float32)\n",
    "\n",
    "# model\n",
    "H_V = tf.matmul(X, W1)+b1\n",
    "H_O = tf.sigmoid(H_V)\n",
    "O_V = tf.matmul(H_O, W2)+b2\n",
    "Y = tf.sigmoid(O_V)\n",
    "\n",
    "learn_rate = 0.1\n",
    "Cost = tf.reduce_mean(-D*tf.math.log(Y)-(1-D)*tf.math.log(1-Y), 1)\n",
    "train = tf.train.GradientDescentOptimizer(learn_rate).minimize(Cost)\n",
    "\n",
    "predict = Y\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(20000):\n",
    "    _train, _Cost = sess.run([train, Cost], feed_dict={X:X_train, D:D_train})\n",
    "\n",
    "_predict = sess.run([predict], feed_dict={X:X_train})\n",
    "print(\"predict=\", _predict)\n",
    "print(\"result=\", np.array(np.array(_predict)>=0.5, np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[-0.12212784]\n",
      " [ 0.        ]]\n",
      "[[0.7 0.6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#A = np.matrix([[0.6,0.4],[0.3,0.8]])\n",
    "#B = np.matrix([[0.0,0.0], [1.0,0.0], [0.0,1.0], [0.0,0.0]])\n",
    "\n",
    "#print(A)\n",
    "#print(B)\n",
    "#AA = np.matmul(A,B)\n",
    "#print(AA)\n",
    "#BB = np.matmul(A,np.transpose(B))\n",
    "#print(BB)\n",
    "#print(AA[0])\n",
    "#print(sigmoid(AA[0]))\n",
    "#print(AA[1])\n",
    "\n",
    "# 가중치를 계산하기 위해서는 배열을 매트릭스(행렬)로 변환해서 계산해야 합니다.\n",
    "\n",
    "\n",
    "#hidden_y = np.matrix([[0.5],[0.5]],[[0.64565631],[0.57444252]],[[0.59868766],[0.68997448]],[[0.5],[0.5]])\n",
    "#hidden_err = np.matrix([[-0.24425569],[-0.30531962]],[[0.14676514],[0.18345642]],[[0.14316259],[0.17895323]],[[-0.24425569],[-0.30531962]])\n",
    "hidden_y = np.matrix([[0.5],[0.5]])\n",
    "hidden_err = np.matrix([[-0.24425569],[-0.30531962]])\n",
    "hidden_delta = np.matrix([[0.0], [0.0]])\n",
    "\n",
    "print(hidden_y[0])\n",
    "print(hidden_y[1])\n",
    "\n",
    "hidden_delta[0] = hidden_y[0] * hidden_err[0]\n",
    "\n",
    "print(hidden_delta)\n",
    "\n",
    "\n",
    "\n",
    "W1 = np.matrix([[0.6, 0.4], [0.3, 0.8]], dtype=float)\n",
    "weight_change = np.matrix([[0.1, 0.2]], dtype=float)\n",
    "print(W1[0] + weight_change)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100000000000000000000000000000000000000000000000000\n",
      " 8663234049605954426644038200675212212900743262211018069459689001 nan]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-790556df9190>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([10**50,19**50,float('NaN')])\n",
    "print(a)\n",
    "#outputs:\n",
    "#array([100000000000000000000000000000000000000000000000000L,\n",
    "#   8663234049605954426644038200675212212900743262211018069459689001L,\n",
    "#   nan], dtype=object)\n",
    "\n",
    "np.isnan(a.astype(float))\n",
    "np.isnan(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78302763 0.73120593 0.76644475 0.72539535] 1\n",
      "[[0.37837005 0.01989266]\n",
      " [0.87833158 0.38781071]]\n"
     ]
    }
   ],
   "source": [
    "W1 = np.matrix([[0.2, 0.3], [0.3, 0.4]], dtype=float)\n",
    "W2 = np.matrix([[0.3, 0.5]], dtype=float)\n",
    "\n",
    "print(np.random.rand(4))\n",
    "ran_w1 = np.random.rand(4)\n",
    "arr_w1 = ran_w1.reshape(2,2)\n",
    "W1 = np.asmatrix(arr_w1, dtype=float)\n",
    "print(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
