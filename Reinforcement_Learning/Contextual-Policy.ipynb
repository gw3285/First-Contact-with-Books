{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 콘테스트 밴딧\n",
    "class contextural_bandit():\n",
    "    def __init__(self):\n",
    "        self.state = 0\n",
    "        # 밴딧들의 손잡이 목록을 작성. 각 밴딧은 각각 손잡이 4, 2, 1이 최적이다.\n",
    "        self.bandits = np.array([[0.2,0,-0.0,-5],[0.1,-5,1,0.25],[-5,5,5,5]])\n",
    "        self.num_bandits = self.bandits.shape[0]\n",
    "        self.num_actions = self.bandits.shape[1]\n",
    "        \n",
    "    def getBandit(self):\n",
    "        # 각각의 에피소드에 대해 랜덤한 상태를 반환\n",
    "        self.state = np.random.randint(0, len(self.bandits))\n",
    "        return self.state\n",
    "    \n",
    "    def pullArm(self, action):\n",
    "        # 랜덤한 수를 얻는다.\n",
    "        bandit = self.bandits[self.state,action]\n",
    "        result = np.random.randn(1)\n",
    "        if result > bandit:\n",
    "            # 양의 보상을 반환한다.\n",
    "            return 1\n",
    "        else:\n",
    "            # 음의 보상을 반환한다.\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정책 기반 에이전트\n",
    "class agent():\n",
    "    def __init__(self, lr, s_size, a_size):\n",
    "        # 네트워크의 피드포워드 부분. 에이전트는 상태를 받아서 액션을 출력한다.\n",
    "        self.state_in = tf.placeholder(shape=[1],dtype=tf.int32)\n",
    "        # Transform numeric labels into onehot_labels using tf.one_hot.\n",
    "        state_in_OH = slim.one_hot_encoding(self.state_in,s_size)\n",
    "        output = slim.fully_connected(state_in_OH,a_size,\n",
    "                                     biases_initializer=None, activation_fn=tf.nn.sigmoid,\n",
    "                                     weights_initializer=tf.ones_initializer())\n",
    "        self.output = tf.reshape(output,[-1])\n",
    "        self.chosen_action = tf.argmax(self.output, 0)\n",
    "        \n",
    "        # 학습 과정을 구한다.\n",
    "        # 비용을 계산하기 위해 보상과 선택된 액션을 네트워크에 피드하고\n",
    "        # 네트워크를 업데이트하는 데에 이를 이용한다.\n",
    "        self.reward_holder = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "        self.action_holder = tf.placeholder(shape=[1], dtype=tf.int32)\n",
    "        self.responsible_weight = tf.slice(self.output, self.action_holder,[1])\n",
    "        self.loss = -(tf.log(self.responsible_weight)*self.reward_holder)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "        self.update = optimizer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ynebu\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:2557: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Mean reward for each of the 3 bandits: [-0.25  0.    0.  ]\n",
      "Mean reward for each of the 3 bandits: [1.5  3.25 3.5 ]\n",
      "Mean reward for each of the 3 bandits: [0.5  8.   7.25]\n",
      "Mean reward for each of the 3 bandits: [ 5.   12.   11.25]\n",
      "Mean reward for each of the 3 bandits: [ 6.75 16.   15.  ]\n",
      "Mean reward for each of the 3 bandits: [10.75 20.5  17.  ]\n",
      "Mean reward for each of the 3 bandits: [14.   23.75 23.  ]\n",
      "Mean reward for each of the 3 bandits: [17.25 28.   27.  ]\n",
      "Mean reward for each of the 3 bandits: [20.25 32.75 29.75]\n",
      "Mean reward for each of the 3 bandits: [22.75 37.5  33.5 ]\n",
      "Mean reward for each of the 3 bandits: [27.   42.5  35.75]\n",
      "Mean reward for each of the 3 bandits: [31.25 45.25 39.25]\n",
      "Mean reward for each of the 3 bandits: [37.   48.25 43.  ]\n",
      "Mean reward for each of the 3 bandits: [41.5  51.25 47.  ]\n",
      "Mean reward for each of the 3 bandits: [45.75 56.5  49.5 ]\n",
      "Mean reward for each of the 3 bandits: [50.75 61.25 52.25]\n",
      "Mean reward for each of the 3 bandits: [54.5  63.25 58.  ]\n",
      "Mean reward for each of the 3 bandits: [59.5  66.25 60.5 ]\n",
      "Mean reward for each of the 3 bandits: [62.75 72.5  63.  ]\n",
      "Mean reward for each of the 3 bandits: [65.75 77.25 65.75]\n",
      "Mean reward for each of the 3 bandits: [70.   82.25 68.5 ]\n",
      "Mean reward for each of the 3 bandits: [74.5  86.25 72.5 ]\n",
      "Mean reward for each of the 3 bandits: [78.5  90.   75.25]\n",
      "Mean reward for each of the 3 bandits: [83.25 92.75 78.75]\n",
      "Mean reward for each of the 3 bandits: [86.75 97.5  82.  ]\n",
      "Mean reward for each of the 3 bandits: [ 90.   102.5   84.75]\n",
      "Mean reward for each of the 3 bandits: [ 95.25 105.5   88.  ]\n",
      "Mean reward for each of the 3 bandits: [ 99.25 109.25  92.25]\n",
      "Mean reward for each of the 3 bandits: [102.25 114.25  95.25]\n",
      "Mean reward for each of the 3 bandits: [106.75 119.5   97.  ]\n",
      "Mean reward for each of the 3 bandits: [110.5  123.5  100.25]\n",
      "Mean reward for each of the 3 bandits: [115.   126.5  103.75]\n",
      "Mean reward for each of the 3 bandits: [119.5  130.   107.25]\n",
      "Mean reward for each of the 3 bandits: [123.75 134.   109.  ]\n",
      "Mean reward for each of the 3 bandits: [128.5  138.   111.75]\n",
      "Mean reward for each of the 3 bandits: [133.25 141.5  114.5 ]\n",
      "Mean reward for each of the 3 bandits: [135.75 144.5  118.5 ]\n",
      "Mean reward for each of the 3 bandits: [139.   148.75 122.  ]\n",
      "Mean reward for each of the 3 bandits: [143.25 152.   125.5 ]\n",
      "Mean reward for each of the 3 bandits: [146.5  156.75 128.5 ]\n",
      "Mean reward for each of the 3 bandits: [150.5  160.75 131.5 ]\n",
      "Mean reward for each of the 3 bandits: [155.5  163.5  134.75]\n",
      "Mean reward for each of the 3 bandits: [159.75 167.5  137.  ]\n",
      "Mean reward for each of the 3 bandits: [162.75 173.   140.  ]\n",
      "Mean reward for each of the 3 bandits: [165.75 177.5  144.  ]\n",
      "Mean reward for each of the 3 bandits: [169.25 181.5  147.  ]\n",
      "Mean reward for each of the 3 bandits: [173.   184.75 150.5 ]\n",
      "Mean reward for each of the 3 bandits: [176.75 189.25 153.75]\n",
      "Mean reward for each of the 3 bandits: [181.25 194.25 156.75]\n",
      "Mean reward for each of the 3 bandits: [185.25 198.   160.5 ]\n",
      "Mean reward for each of the 3 bandits: [188.5  202.   164.25]\n",
      "Mean reward for each of the 3 bandits: [190.75 207.   168.  ]\n",
      "Mean reward for each of the 3 bandits: [194.   211.   171.25]\n",
      "Mean reward for each of the 3 bandits: [196.5  214.5  176.25]\n",
      "Mean reward for each of the 3 bandits: [200.   218.   180.75]\n",
      "Mean reward for each of the 3 bandits: [203.75 221.25 183.25]\n",
      "Mean reward for each of the 3 bandits: [207.25 225.75 186.75]\n",
      "Mean reward for each of the 3 bandits: [211.   228.75 190.  ]\n",
      "Mean reward for each of the 3 bandits: [214.75 232.25 192.25]\n",
      "Mean reward for each of the 3 bandits: [218.25 236.5  196.  ]\n",
      "Mean reward for each of the 3 bandits: [221.25 240.   201.5 ]\n",
      "Mean reward for each of the 3 bandits: [223.5  245.   205.25]\n",
      "Mean reward for each of the 3 bandits: [227.25 249.   209.5 ]\n",
      "Mean reward for each of the 3 bandits: [231.75 252.5  213.5 ]\n",
      "Mean reward for each of the 3 bandits: [236.25 256.   216.5 ]\n",
      "Mean reward for each of the 3 bandits: [239.75 259.5  219.5 ]\n",
      "Mean reward for each of the 3 bandits: [241.5  265.5  224.25]\n",
      "Mean reward for each of the 3 bandits: [245.   269.   228.25]\n",
      "Mean reward for each of the 3 bandits: [249.   274.   231.75]\n",
      "Mean reward for each of the 3 bandits: [252.5  277.   236.25]\n",
      "Mean reward for each of the 3 bandits: [255.5  281.75 240.5 ]\n",
      "Mean reward for each of the 3 bandits: [259.5  286.25 242.5 ]\n",
      "Mean reward for each of the 3 bandits: [263.   292.   245.75]\n",
      "Mean reward for each of the 3 bandits: [267.5  296.25 248.  ]\n",
      "Mean reward for each of the 3 bandits: [271.75 299.75 252.25]\n",
      "Mean reward for each of the 3 bandits: [275.25 303.75 255.75]\n",
      "Mean reward for each of the 3 bandits: [279.25 308.5  259.  ]\n",
      "Mean reward for each of the 3 bandits: [283.25 313.25 260.25]\n",
      "Mean reward for each of the 3 bandits: [285.   317.   266.75]\n",
      "Mean reward for each of the 3 bandits: [288.75 320.25 270.25]\n",
      "Mean reward for each of the 3 bandits: [292.5  323.5  274.75]\n",
      "Mean reward for each of the 3 bandits: [294.75 327.5  279.5 ]\n",
      "Mean reward for each of the 3 bandits: [299.5  331.25 282.5 ]\n",
      "Mean reward for each of the 3 bandits: [302.75 334.5  287.  ]\n",
      "Mean reward for each of the 3 bandits: [306.5  337.5  290.25]\n",
      "Mean reward for each of the 3 bandits: [311.25 340.75 294.25]\n",
      "Mean reward for each of the 3 bandits: [314.75 346.   297.  ]\n",
      "Mean reward for each of the 3 bandits: [319.75 350.25 299.75]\n",
      "Mean reward for each of the 3 bandits: [323.   354.5  303.25]\n",
      "Mean reward for each of the 3 bandits: [327.75 359.25 306.25]\n",
      "Mean reward for each of the 3 bandits: [332.5  364.   308.75]\n",
      "Mean reward for each of the 3 bandits: [337.5  367.   312.75]\n",
      "Mean reward for each of the 3 bandits: [341.25 371.5  315.5 ]\n",
      "Mean reward for each of the 3 bandits: [345.   374.5  318.25]\n",
      "Mean reward for each of the 3 bandits: [347.5  378.25 322.5 ]\n",
      "Mean reward for each of the 3 bandits: [350.25 384.   325.  ]\n",
      "Mean reward for each of the 3 bandits: [354.75 389.   326.5 ]\n",
      "Mean reward for each of the 3 bandits: [357.75 396.   329.  ]\n",
      "Mean reward for each of the 3 bandits: [361.   401.5  331.75]\n",
      "Mean reward for each of the 3 bandits: [365.25 403.75 335.25]\n",
      "Mean reward for each of the 3 bandits: [369.   409.   338.25]\n",
      "Mean reward for each of the 3 bandits: [373.   412.   342.75]\n",
      "Mean reward for each of the 3 bandits: [377.5  417.5  344.25]\n",
      "Mean reward for each of the 3 bandits: [382.5  422.5  346.25]\n",
      "Mean reward for each of the 3 bandits: [387.   425.75 350.  ]\n",
      "Mean reward for each of the 3 bandits: [391.25 429.75 353.25]\n",
      "Mean reward for each of the 3 bandits: [394.25 434.25 356.75]\n",
      "Mean reward for each of the 3 bandits: [398.25 438.5  360.5 ]\n",
      "Mean reward for each of the 3 bandits: [401.75 443.   364.5 ]\n",
      "Mean reward for each of the 3 bandits: [405.   446.75 369.  ]\n",
      "Mean reward for each of the 3 bandits: [408.25 450.   374.  ]\n",
      "Mean reward for each of the 3 bandits: [413.   453.   377.75]\n",
      "Mean reward for each of the 3 bandits: [415.5  458.25 382.  ]\n",
      "Mean reward for each of the 3 bandits: [419.25 461.75 385.75]\n",
      "Mean reward for each of the 3 bandits: [422.75 464.5  390.5 ]\n",
      "Mean reward for each of the 3 bandits: [426.   469.   395.25]\n",
      "Mean reward for each of the 3 bandits: [429.   473.75 399.5 ]\n",
      "Mean reward for each of the 3 bandits: [433.   477.75 403.  ]\n",
      "Mean reward for each of the 3 bandits: [439.5  481.   405.25]\n",
      "Mean reward for each of the 3 bandits: [444.25 486.   408.  ]\n",
      "Mean reward for each of the 3 bandits: [447.25 489.25 412.75]\n",
      "Mean reward for each of the 3 bandits: [452.25 491.75 416.25]\n",
      "Mean reward for each of the 3 bandits: [455.25 494.5  421.5 ]\n",
      "Mean reward for each of the 3 bandits: [460.75 497.5  425.  ]\n",
      "Mean reward for each of the 3 bandits: [463.5  501.25 428.  ]\n",
      "Mean reward for each of the 3 bandits: [467.25 503.25 432.25]\n",
      "Mean reward for each of the 3 bandits: [470.75 507.25 436.25]\n",
      "Mean reward for each of the 3 bandits: [475.   511.   439.25]\n",
      "Mean reward for each of the 3 bandits: [479.75 515.25 441.25]\n",
      "Mean reward for each of the 3 bandits: [484.5  518.5  444.75]\n",
      "Mean reward for each of the 3 bandits: [488.   520.25 450.  ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward for each of the 3 bandits: [490.75 524.25 453.25]\n",
      "Mean reward for each of the 3 bandits: [495.   527.   457.25]\n",
      "Mean reward for each of the 3 bandits: [498.25 530.5  460.  ]\n",
      "Mean reward for each of the 3 bandits: [502.75 534.75 463.75]\n",
      "Mean reward for each of the 3 bandits: [505.   539.   467.25]\n",
      "Mean reward for each of the 3 bandits: [508.75 543.25 470.75]\n",
      "Mean reward for each of the 3 bandits: [513.   545.75 474.5 ]\n",
      "Mean reward for each of the 3 bandits: [516.5  550.25 477.  ]\n",
      "Mean reward for each of the 3 bandits: [520.75 554.   480.5 ]\n",
      "Mean reward for each of the 3 bandits: [523.5  557.75 485.5 ]\n",
      "Mean reward for each of the 3 bandits: [527.75 562.   489.  ]\n",
      "Mean reward for each of the 3 bandits: [532.5  565.5  492.25]\n",
      "Mean reward for each of the 3 bandits: [537.25 567.5  495.5 ]\n",
      "Mean reward for each of the 3 bandits: [542.   572.25 498.  ]\n",
      "Mean reward for each of the 3 bandits: [546.5  575.5  502.25]\n",
      "Mean reward for each of the 3 bandits: [551.25 577.25 506.25]\n",
      "Mean reward for each of the 3 bandits: [553.25 581.5  512.  ]\n",
      "Mean reward for each of the 3 bandits: [557.5  586.   515.25]\n",
      "Mean reward for each of the 3 bandits: [561.5  589.5  519.75]\n",
      "Mean reward for each of the 3 bandits: [564.75 592.5  525.  ]\n",
      "Mean reward for each of the 3 bandits: [569.5  596.25 528.5 ]\n",
      "Mean reward for each of the 3 bandits: [575.   598.5  532.25]\n",
      "Mean reward for each of the 3 bandits: [578.5  603.25 536.  ]\n",
      "Mean reward for each of the 3 bandits: [582.5  607.   540.25]\n",
      "Mean reward for each of the 3 bandits: [588.25 609.25 543.75]\n",
      "Mean reward for each of the 3 bandits: [592.5  613.75 546.5 ]\n",
      "Mean reward for each of the 3 bandits: [595.75 618.   551.  ]\n",
      "Mean reward for each of the 3 bandits: [599.75 621.   555.  ]\n",
      "Mean reward for each of the 3 bandits: [603.   624.   558.75]\n",
      "Mean reward for each of the 3 bandits: [607.   627.   563.75]\n",
      "Mean reward for each of the 3 bandits: [610.25 630.25 567.75]\n",
      "Mean reward for each of the 3 bandits: [614.25 633.75 572.25]\n",
      "Mean reward for each of the 3 bandits: [616.25 638.25 577.25]\n",
      "Mean reward for each of the 3 bandits: [619.   642.75 579.5 ]\n",
      "Mean reward for each of the 3 bandits: [622.25 646.5  584.5 ]\n",
      "Mean reward for each of the 3 bandits: [627.   649.25 589.5 ]\n",
      "Mean reward for each of the 3 bandits: [631.   652.5  593.25]\n",
      "Mean reward for each of the 3 bandits: [633.75 657.   597.  ]\n",
      "Mean reward for each of the 3 bandits: [638.5  660.25 599.5 ]\n",
      "Mean reward for each of the 3 bandits: [641.25 664.   604.  ]\n",
      "Mean reward for each of the 3 bandits: [644.5  668.   607.75]\n",
      "Mean reward for each of the 3 bandits: [649.   672.5  610.25]\n",
      "Mean reward for each of the 3 bandits: [652.25 676.   614.5 ]\n",
      "Mean reward for each of the 3 bandits: [656.25 679.25 618.25]\n",
      "Mean reward for each of the 3 bandits: [660.75 685.25 619.75]\n",
      "Mean reward for each of the 3 bandits: [664.5  689.   624.25]\n",
      "Mean reward for each of the 3 bandits: [668.5  692.25 628.  ]\n",
      "Mean reward for each of the 3 bandits: [673.75 694.5  630.  ]\n",
      "Mean reward for each of the 3 bandits: [677.25 698.5  634.  ]\n",
      "Mean reward for each of the 3 bandits: [681.   702.25 638.5 ]\n",
      "Mean reward for each of the 3 bandits: [685.25 706.   642.5 ]\n",
      "Mean reward for each of the 3 bandits: [687.75 711.5  646.  ]\n",
      "Mean reward for each of the 3 bandits: [690.5  716.   649.75]\n",
      "Mean reward for each of the 3 bandits: [693.5  720.75 653.  ]\n",
      "Mean reward for each of the 3 bandits: [698.   723.   656.25]\n",
      "Mean reward for each of the 3 bandits: [701.5  727.   660.25]\n",
      "Mean reward for each of the 3 bandits: [705.5  731.   663.75]\n",
      "Mean reward for each of the 3 bandits: [711.   735.   666.25]\n",
      "Mean reward for each of the 3 bandits: [714.75 738.5  670.  ]\n",
      "Mean reward for each of the 3 bandits: [719.5  742.   672.25]\n",
      "Mean reward for each of the 3 bandits: [722.75 746.75 674.75]\n",
      "Mean reward for each of the 3 bandits: [727.75 749.25 678.75]\n",
      "Mean reward for each of the 3 bandits: [731.75 752.75 682.75]\n",
      "Mean reward for each of the 3 bandits: [735.75 756.5  686.5 ]\n",
      "Mean reward for each of the 3 bandits: [741.   758.5  691.25]\n",
      "Mean reward for each of the 3 bandits: [745.   762.5  693.75]\n",
      "Mean reward for each of the 3 bandits: [748.25 766.5  697.5 ]\n",
      "Mean reward for each of the 3 bandits: [752.5  769.75 701.5 ]\n",
      "Mean reward for each of the 3 bandits: [757.25 774.5  704.  ]\n",
      "The agent thinks action 3 fro bandit 1 is the most promising....\n",
      "... and it was right!\n",
      "The agent thinks action 1 fro bandit 2 is the most promising....\n",
      "... and it was right!\n",
      "The agent thinks action 0 fro bandit 3 is the most promising....\n",
      "... and it was right!\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로 그래프를 리셋한다.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 밴딧을 로드한다.\n",
    "cBandit = contextural_bandit()\n",
    "# 에이전트를 로드한다.\n",
    "myAgent = agent(lr=0.001, s_size=cBandit.num_bandits, a_size=cBandit.num_actions)\n",
    "# 네트워크 내부를 들여다보기 위해 평가할 가중치\n",
    "# Return all variables created with trainable=True\n",
    "# When passed trainable=True, the Variable() constructor automatically adds new variables to the grapth collection\n",
    "weights = tf.trainable_variables()[0]\n",
    "\n",
    "# 에이전트를 학습시킬 전체 에피소드 수 설정\n",
    "total_episodes = 10000\n",
    "# 밴딧에 대한 점수판을 0으로 설정\n",
    "total_reward = np.zeros([cBandit.num_bandits, cBandit.num_actions])\n",
    "# 랜덤한 액션을 취할 가능성 설정\n",
    "e = 0.1\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 텐서플로 그래프 론칭\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    i = 0\n",
    "    while i < total_episodes:\n",
    "        # 환경으로부터 상태 가져오기\n",
    "        s = cBandit.getBandit()\n",
    "        # 네트워크로부터 랜덤한 액션 또는 하나의 액션을 선택한다.\n",
    "        if np.random.rand(1) < e:\n",
    "            action = np.random.randint(cBandit.num_actions)\n",
    "        else:\n",
    "            action = sess.run(myAgent.chosen_action, feed_dict={myAgent.state_in:[s]})\n",
    "        \n",
    "        # 주어진 밴딧에 대해 액션을 취한 데 대한 보상을 얻는다.\n",
    "        reward = cBandit.pullArm(action)\n",
    "        \n",
    "        # 네트워크를 업데이트한다.\n",
    "        feed_dict = {myAgent.reward_holder:[reward],\n",
    "                    myAgent.action_holder:[action], myAgent.state_in:[s]}\n",
    "        _,ww = sess.run([myAgent.update, weights], feed_dict=feed_dict)\n",
    "        \n",
    "        # 보상의 총계 업데이트\n",
    "        total_reward[s, action] += reward\n",
    "        if i % 50 == 0:\n",
    "            print(\"Mean reward for each of the \" + str(cBandit.num_bandits) + \" bandits: \" + str(np.mean(total_reward, axis=1)))\n",
    "            \n",
    "        i+=1\n",
    "        \n",
    "for a in range(cBandit.num_bandits):\n",
    "    print(\"The agent thinks action \" + str(np.argmax(ww[a]+1)) + \" fro bandit \" + str(a+1) + \" is the most promising....\")\n",
    "    if np.argmax(ww[a]) == np.argmin(cBandit.bandits[a]):\n",
    "        print(\"... and it was right!\")\n",
    "    else:\n",
    "        print(\"... and it was wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
